





# For performing operation on dataframe
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# For Model Evaluation
from sklearn.metrics import classification_report, confusion_matrix

# Importing objects to build NN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# For visualization
import seaborn as sns
import matplotlib.pyplot as plt





taxi_df = pd.read_csv("Taxi-cancellation-case.csv")


taxi_df.head(10)








# For all the datetime columns
for col in ['from_date', 'to_date', 'booking_created']:
    taxi_df[col] = pd.to_datetime(taxi_df[col], format = '%m/%d/%y %H:%M', errors='coerce')


taxi_df['from_area_id'] = taxi_df['from_area_id'].astype('Int64')
taxi_df['to_area_id'] = taxi_df['to_area_id'].astype('Int64')


taxi_df.info()


taxi_df.info()





sns.barplot(taxi_df, x = "Car_Cancellation", y = "user_id")





# This library help us visualize missing values :)
import missingno as msno
msno.matrix(taxi_df[taxi_df.columns[2:-1]])


# Percentage of missing values
missing_percentage = (taxi_df.isnull().sum() / len(taxi_df)) * 100

# Filter columns with missing values
missing_percentage = missing_percentage[missing_percentage > 0]
missing_percentage





# Dropping the following features 'package_id', 'from_city_id', 'to_city_id'
taxi_df.drop(['package_id', 'from_city_id', 'to_city_id'], axis = 1, inplace = True)





taxi_df.columns[2:-1].shape


# Selecting the features to visualize their distribution
selected_features = taxi_df.columns[2:-1]

# Creating a 4x4 subplot 
fig, axes = plt.subplots(nrows = 4, ncols = 4, figsize = (16,16))
axes = axes.flatten()

for i, feature in enumerate(selected_features):
    sns.kdeplot(data = taxi_df, x = feature, hue = "Car_Cancellation", ax=axes[i], fill=True)
    axes[i].set_title(feature, fontsize=12)
    axes[i].set_xlabel('Values')
    axes[i].set_ylabel('Density')

plt.tight_layout(pad=2.0, h_pad=1.0)








X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)





# Scaling the data so that model can be train on features with same scale of value.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)





model = Sequential([
    Dense( /, input_dim = , activation = 'relu'),
    Dense( /, input_dim = , activation = 'relu'),
    Dense( 2, input_dim = , activation = 'sigmoid'),
])
